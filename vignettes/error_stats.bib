% Encoding: UTF-8

@Article{Kim2016,
  author    = {Sungil Kim and Heeyoung Kim},
  title     = {A new metric of absolute percentage error for intermittent demand forecasts},
  journal   = {International Journal of Forecasting},
  year      = {2016},
  month     = {jul},
    keywords  = {Accuracy measure, Forecast evaluation, Intermittent demand, MAPE, relevant},
  volume    = {32},
  number    = {3},
  pages     = {669--679},
  publisher = {Elsevier},
  doi       = {10.1016/j.ijforecast.2015.12.003},
  url       = {https://doi.org/10.1016/j.ijforecast.2015.12.003},
}

@Article{Makridakis1993,
  author    = {Spyros Makridakis},
  title     = {Accuracy measures: theoretical and practical concerns},
  journal   = {International Journal of Forecasting},
  year      = {1993},
  volume    = {9},
  number    = {4},
  pages     = {527--529},
  month     = {dec},
  abstract  = {There has been renewed concern recently
(Fildes (1992); Armstrong and Collopy (1992)]
about the most appropriate accuracy measure to
be used for evaluating forecasting methods and
for reporting error statistics. The purpose of this
note is to examine accuracy measures from a
theoretical and practical point of view and to
suggest a modified form of MAPE as the most
appropriate measure satisfying both theoretical
and practical concerns while allowing meaningful
relative comparisons.

Accuracy measures, error statistics or mea-
sures, and loss functions are alternative ways of
conveying information about the ability of a
certain forecasting method to predict actual data,
either when a model is fitted to such data, or for
future periods (post-sample) whose values have
not been used to develop the forecasting model.
Research has shown that post-sample accuracies
are not always related to those of the model that
best fits available historical data [Makridakis
(1986)]. },
  doi       = {10.1016/0169-2070(93)90079-3},
  publisher = {Elsevier {BV}},
  url       = {https://www.sciencedirect.com/science/article/pii/0169207093900793},
}

@Article{Chen2017,
  author    = {Chao Chen and Jamie Twycross and Jonathan M. Garibaldi},
  title     = {A new accuracy measure based on bounded relative error for time series forecasting},
  journal   = {{PLOS} {ONE}},
  year      = {2017},
  volume    = {12},
  number    = {3},
  pages     = {e0174202},
  month     = {mar},
  abstract  = {Many accuracy measures have been proposed in the past for time series forecasting comparisons. However, many of these measures suffer from one or more issues such as poor resistance to outliers and scale dependence. In this paper, while summarising commonly used accuracy measures, a special review is made on the symmetric mean absolute percentage error. Moreover, a new accuracy measure called the Unscaled Mean Bounded Relative Absolute Error (UMBRAE), which combines the best features of various alternative measures, is proposed to address the common issues of existing measures. A comparative evaluation on the proposed and related measures has been made with both synthetic and real-world data. The results indicate that the proposed measure, with user selectable benchmark, performs as well as or better than other measures on selected criteria. Though it has been commonly accepted that there is no single best accuracy measure, we suggest that UMBRAE could be a good choice to evaluate forecasting methods, especially for cases where measures based on geometric mean of relative errors, such as the geometric mean relative absolute error, are preferred.},
  doi       = {10.1371/journal.pone.0174202},
  editor    = {Zhong-Ke Gao},
  publisher = {Public Library of Science ({PLoS})},
  url       = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0174202},
}

@Article{Kobayashi2000,
  author    = {Kazuhiko Kobayashi and Moin Us Salam},
  title     = {Comparing Simulated and Measured Values Using Mean Squared Deviation and its Components},
  journal   = {Agronomy Journal},
  year      = {2000},
  volume    = {92},
  number    = {2},
  pages     = {345},
  abstract  = {When output (x) of a mechanistic model is compared with measurement (y), it is common practice to calculate the correlation coefficient between x and y, and to regress y on x. There are, however, problems in this approach. The assumption of the regression, that y is linearly related to x, is not guaranteed and is unnecessary for the x-y comparison. The correlation and regression coefficients are not explicitly related to other commonly used statistics [e.g., root mean squared deviation (RMSD)]. We present an approach based on the mean squared deviation (MSD = RMSD2) and show that it is better suited to the x-y comparison than regression. Mean squared deviation is the sum of three components: squared bias (SB), squared difference between standard deviations (SDSD), and lack of correlation weighted by the standard deviations (LCS), To show examples, the MSD-based analysis was applied to simulation vs. measurement comparisons in literature, and the results were compared with those from regression analysis, The analysis of MSD clearly identified the simulation vs. measurement contrasts with larger deviation than others; the correlation-regression approach tended to focus on the contrasts with lower correlation and regression line far front the equality line. It was also shown that results of the MSD-based analysis mere easier to interpret than those of regression analysis. This is because the three MSD components are simply additive and all constituents of the MSD components are explicit. This approach will be useful to quantify the deviation of calculated values obtained with this model from measurements.},
  doi       = {10.1007/s100870050043},
  publisher = {Springer Nature},
  url       = {https://www.researchgate.net/publication/243112181_Comparing_Simulated_and_Measured_Values_Using_Mean_Squared_Deviation_and_Its_Components},
}

@Article{Myttenaere2016,
  author    = {Arnaud de Myttenaere and Boris Golden and B{\'{e}}n{\'{e}}dicte Le Grand and Fabrice Rossi},
  title     = {Mean Absolute Percentage Error for regression models},
  journal   = {Neurocomputing},
  year      = {2016},
  volume    = {192},
  pages     = {38--48},
  month     = {jun},
  abstract  = {We study in this paper the consequences of using the Mean Absolute Percentage Error (MAPE) as a measure of quality for regression models. We prove the existence of an optimal MAPE model and we show the universal consistency of Empirical Risk Minimization based on the MAPE. We also show that finding the best model under the MAPE is equivalent to doing weighted Mean Absolute Error (MAE) regression, and we apply this weighting strategy to kernel regression. The behavior of the MAPE kernel regression is illustrated on simulated data.},
  doi       = {10.1016/j.neucom.2015.12.114},
  keywords  = {Mean Absolute Percentage Error, Empirical Risk Minimization, Consistency, Optimization, Kernel regression},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016/j.neucom.2015.12.114},
}

@Article{Syntetos2013,
  author    = {Aris Syntetos and David Lengu and Mohamed Zied Babai},
  title     = {A note on the demand distributions of spare parts},
  journal   = {International Journal of Production Research},
  year      = {2013},
  volume    = {51},
  number    = {21},
  pages     = {6356--6358},
  month     = {nov},
  doi       = {10.1080/00207543.2013.798050},
  publisher = {Informa {UK} Limited},
}

@Article{Armstrong1992,
  author    = {J.Scott Armstrong and Fred Collopy},
  title     = {Error measures for generalizing about forecasting methods: Empirical comparisons},
  journal   = {International Journal of Forecasting},
  year      = {1992},
  volume    = {8},
  number    = {1},
  pages     = {69--80},
  month     = {jun},
  abstract  = {This study evaluated measures for making comparisons of errors across time series. We analyzed 90 annual and 101 quarterly economic time series. We judged error measures on reliability, construct validity, sensitivity to small changes, protection against outliers, and their relationship to decision making. The results lead us to recommend the Geometric Mean of the Relative Absolute Error (GMRAE) when the task involves calibrating a model for a set of time series. The GMRAE compares the absolute error of a given method to that from the random walk forecast. For selecting the most accurate methods, we recommend the Median RAE (MdRAE) when few series are available and the Median Absolute Percentage Error (MdAPE) otherwise. The Root Mean Square Error (RMSE) is not reliable, and is therefore inappropriate for comparing accuracy across series.},
  doi       = {10.1016/0169-2070(92)90008-w},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016/0169-2070(92)90008-W},
}

@Comment{jabref-meta: databaseType:bibtex;}